# -*- coding: utf-8 -*-
"""TMDB Movie Data 2009-2025.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13VzYEQG_a0uH6qz0xhdr3YdqiiBwiBG3
"""

import requests
import time
import csv
import datetime
import os

# --- Configuration ---
API_KEY = "604e6c648806ab67a37a0155a05ed956"  # Your v3 API Key
BASE_URL = "https://api.themoviedb.org/3"
START_YEAR = 2009
END_YEAR = 2025  # Will include 2025
OUTPUT_FILE = 'tmdb_movie_data_2009-2025.csv'

# Define the headers for our CSV file
FIELDNAMES = [
    'tmdb_id',
    'title',
    'release_date',
    'budget',
    'runtime',
    'tmdb_popularity',
    'tmdb_vote_count',
    'tmdb_vote_average',
    'is_sequel',
    'director_name',
    'director_popularity',
    'lead_actor_name',
    'lead_actor_popularity',
    'genres',
    'production_studios',
    'mpaa_rating',
    'release_month',
    'is_holiday_release'
]

# --- Helper Functions ---

def get_us_certification(release_dates_data):
    """Parses the release_dates endpoint to find the US MPAA rating."""
    try:
        for country in release_dates_data.get('results', []):
            if country.get('iso_3166_1') == 'US':
                # Find the first non-empty certification
                for release in country.get('release_dates', []):
                    if release.get('certification'):
                        return release.get('certification')
        return 'NR'  # Not Rated
    except Exception:
        return 'NR'

def get_movie_data(movie_id):
    """
    Fetches and parses all required data for a single movie ID.
    Makes 3 API calls: details, credits, and release_dates.
    """
    # 1. Get main movie details
    try:
        details_params = {'api_key': API_KEY}
        details_res = requests.get(f"{BASE_URL}/movie/{movie_id}", params=details_params)
        details_res.raise_for_status()
        details = details_res.json()
        time.sleep(0.1)  # Rate limit courtesy
    except requests.RequestException as e:
        print(f"  [Error] Could not get details for ID {movie_id}: {e}")
        return None
    # 2. Get credits (cast/crew)
    try:
        credits_params = {'api_key': API_KEY}
        credits_res = requests.get(f"{BASE_URL}/movie/{movie_id}/credits", params=credits_params)
        credits_res.raise_for_status()
        credits = credits_res.json()
        time.sleep(0.1)  # Rate limit courtesy
    except requests.RequestException:
        credits = {}  # Continue even if credits fail
    # 3. Get release dates (for MPAA rating)
    try:
        release_params = {'api_key': API_KEY}
        release_res = requests.get(f"{BASE_URL}/movie/{movie_id}/release_dates", params=release_params)
        release_res.raise_for_status()
        release_dates = release_res.json()
        time.sleep(0.1)  # Rate limit courtesy
    except requests.RequestException:
        release_dates = {}  # Continue even if release dates fail

    # --- Parse all the data into a single dictionary ---
    try:
        # Director
        director_name = 'Unknown'
        director_popularity = 0.0
        for person in credits.get('crew', []):
            if person.get('job') == 'Director':
                director_name = person.get('name', 'Unknown')
                director_popularity = person.get('popularity', 0.0)
                break  # Take the first director listed

        # Lead Actor
        lead_actor_name = 'Unknown'
        lead_actor_popularity = 0.0
        if credits.get('cast') and len(credits['cast']) > 0:
            lead_actor_name = credits['cast'][0].get('name', 'Unknown')
            lead_actor_popularity = credits['cast'][0].get('popularity', 0.0)

        # Genres
        genres = '|'.join([g['name'] for g in details.get('genres', [])])

        # Studios
        studios = '|'.join([s['name'] for s in details.get('production_companies', [])])

        # MPAA Rating
        mpaa_rating = get_us_certification(release_dates)

        # Date features
        release_date = details.get('release_date', '')
        release_month = 0
        is_holiday_release = 0
        if release_date:
            try:
                date_obj = datetime.datetime.strptime(release_date, '%Y-%m-%d').date()
                release_month = date_obj.month
                if release_month in [11, 12]:  # November or December
                    is_holiday_release = 1
            except ValueError:
                pass  # Keep defaults if date is malformed

        # Assemble the row
        movie_row = {
            'tmdb_id': movie_id,
            'title': details.get('title', ''),
            'release_date': release_date,
            'budget': details.get('budget', 0),
            'runtime': details.get('runtime', 0),
            'tmdb_popularity': details.get('popularity', 0.0),
            'tmdb_vote_count': details.get('vote_count', 0),
            'tmdb_vote_average': details.get('vote_average', 0.0),
            'is_sequel': 1 if details.get('belongs_to_collection') else 0,
            'director_name': director_name,
            'director_popularity': director_popularity,
            'lead_actor_name': lead_actor_name,
            'lead_actor_popularity': lead_actor_popularity,
            'genres': genres,
            'production_studios': studios,
            'mpaa_rating': mpaa_rating,
            'release_month': release_month,
            'is_holiday_release': is_holiday_release
        }
        return movie_row

    except Exception as e:
        print(f"  [Error] Failed to parse data for movie ID {movie_id}: {e}")
        return None

# --- Main Script ---

def discover_movies():
    """
    Main function to loop through years and pages to discover all movies.
    """
    print(f"Starting movie discovery from {START_YEAR} to {END_YEAR}...")

    # Check if file exists to decide on writing headers
    file_exists = os.path.isfile(OUTPUT_FILE)

    with open(OUTPUT_FILE, 'a', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=FIELDNAMES)
        if not file_exists:
            writer.writeheader()  # Write headers only if file is new

        # Loop through each year
        for year in range(START_YEAR, END_YEAR + 1):
            # The TMDB API limits pagination to 500 pages
            for page in range(1, 501):
                print(f"--- Processing Year: {year}, Page: {page} ---")

                discover_params = {
                    'api_key': API_KEY,
                    'primary_release_year': year,
                    'page': page,
                    'with_origin_country': 'US', # Filter for "Hollywood"
                    'original_language': 'en',   # Filter for "Hollywood"
                    'sort_by': 'popularity.desc',
                    'vote_count.gte': 50 # Filter out very obscure movies
                }

                try:
                    res = requests.get(f"{BASE_URL}/discover/movie", params=discover_params)
                    res.raise_for_status()  # Raise an error for bad responses (4xx, 5xx)
                    data = res.json()
                except requests.RequestException as e:
                    print(f"  [Error] Failed to get discover page: {e}. Skipping page.")
                    time.sleep(5) # Wait before retrying next page
                    continue

                movies = data.get('results', [])
                if not movies:
                    print(f"No more movies found for {year}. Moving to next year.")
                    break  # No more results for this year, break page loop

                # Process each movie found on the discover page
                for movie_stub in movies:
                    movie_id = movie_stub['id']

                    # Check for budget and release date before processing
                    # This saves API calls on movies without essential data
                    if movie_stub.get('release_date') is None or not movie_stub.get('release_date'):
                        print(f"  Skipping ID {movie_id} ('{movie_stub.get('title')}') - No release date.")
                        continue

                    print(f"  Fetching details for ID {movie_id} ('{movie_stub.get('title')}')")
                    movie_row_data = get_movie_data(movie_id)

                    if movie_row_data:
                        # Filter out movies with no budget
                        if movie_row_data['budget'] == 0:
                            print(f"  Skipping ID {movie_id} ('{movie_row_data['title']}') - Budget is 0.")
                        else:
                            writer.writerow(movie_row_data)
                            print(f"  SUCCESS: Added '{movie_row_data['title']}' to CSV.")

                # Be polite to the API
                # time.sleep(0.5) # Wait half a second between *pages*

if __name__ == "__main__":
    discover_movies()
    print("--- Script Finished ---")
    print(f"Data saved to {OUTPUT_FILE}")